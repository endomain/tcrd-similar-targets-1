color=term),
size=0.5,
alpha=0.2) +
geom_point() +
geom_smooth() +
facet_wrap(~term) +
scale_x_date(labels=date_format("%Y-%m"))+
scale_colour_brewer(palette="Set1")+
ggtitle("TF-IDF for Words ")+
theme(legend.position="none")
nytimes_tf_idf %>%
filter(term %in% c("trump","obama","clinton","health","obamacar","russia","email")) %>%
ggplot(aes(x=date,
y=tf_idf,
color=term),
size=0.5,
alpha=0.2) +
geom_point() +
geom_smooth() +
facet_wrap(~term) +
scale_x_date(labels=date_format("%Y-%m"))+
scale_colour_brewer(palette="Set1")+
ggtitle("TF-IDF for Words ")+
theme(legend.position="none")
nytimes_tf_idf %>%
filter(term %in% c("trump","obama","clinton","health","obamacar","russia")) %>%
ggplot(aes(x=date,
y=tf_idf,
color=term),
size=0.5,
alpha=0.2) +
geom_point() +
geom_smooth() +
facet_wrap(~term) +
scale_x_date(labels=date_format("%Y-%m"))+
scale_colour_brewer(palette="Set1")+
ggtitle("TF-IDF for Words ")+
theme(legend.position="none")
nytimes_tf_idf %>%
filter(term %in% c("trump","obama","clinton","health","obamacar","russia")) %>%
ggplot(aes(x=date,
y=tf_idf,
color=term),
size=0.5,
alpha=0.2) +
geom_point() +
geom_smooth() +
facet_wrap(~term) +
scale_x_date(labels=date_format("%Y-%m"))+
scale_colour_brewer(palette="Paired")+
ggtitle("TF-IDF for Words ")+
theme(legend.position="none")
nytimes_tf_idf %>%
filter(term %in% c("trump","obama","clinton","health","obamacar","russia")) %>%
ggplot(aes(x=date,
y=tf_idf,
color=term),
size=0.5,
alpha=0.2) +
geom_point() +
geom_smooth() +
facet_wrap(~term) +
scale_x_date(labels=date_format("%Y-%m"))+
scale_colour_brewer(palette="Accent")+
ggtitle("TF-IDF for Words ")+
theme(legend.position="none")
nytimes_tf_idf %>%
filter(term %in% c("trump","obama","clinton","health","obamacar","russia")) %>%
ggplot(aes(x=date,
y=tf_idf,
color=term),
size=0.5,
alpha=0.5) +
geom_point() +
geom_smooth() +
facet_wrap(~term) +
scale_x_date(labels=date_format("%Y-%m"))+
scale_colour_brewer(palette="Accent")+
ggtitle("TF-IDF for Words ")+
theme(legend.position="none")
nytimes_tf_idf %>%
filter(term %in% c("trump","obama","clinton","health","obamacar","russia")) %>%
ggplot(aes(x=date,
y=tf_idf,
color=term),
size=0.5,
alpha=0.5) +
geom_point() +
geom_smooth() +
facet_wrap(~term) +
scale_x_date(labels=date_format("%Y-%m"))+
scale_colour_brewer(palette="Set2")+
ggtitle("TF-IDF for Words ")+
theme(legend.position="none")
nytimes_tf_idf %>%
filter(term %in% c("trump","obama","clinton","health","obamacar","russia")) %>%
ggplot(aes(x=date,
y=tf_idf,
color=term),
size=0.5,
alpha=0.5) +
geom_point() +
geom_smooth() +
facet_wrap(~term) +
scale_x_date(labels=date_format("%Y-%m"))+
scale_colour_brewer(palette="Paired")+
ggtitle("TF-IDF for Words ")+
theme(legend.position="none")
nytimes_tf_idf %>%
filter(term %in% c("trump","obama","clinton","health","obamacar","russia")) %>%
ggplot(aes(x=date,
y=tf_idf,
color=term),
size=0.5,
alpha=1) +
geom_point() +
geom_smooth() +
facet_wrap(~term) +
scale_x_date(labels=date_format("%Y-%m"))+
scale_colour_brewer(palette="Paired")+
ggtitle("TF-IDF for Words ")+
theme(legend.position="none")
nytimes_tf_idf %>%
filter(term %in% c("trump","obama","clinton","health","obamacar","russia")) %>%
ggplot(aes(x=date,
y=tf_idf,
color=term),
size=0.5,
alpha=1) +
geom_point() +
geom_smooth() +
facet_wrap(~term) +
scale_x_date(labels=date_format("%Y-%m"))+
scale_colour_brewer(palette="Set1")+
ggtitle("TF-IDF for Words ")+
theme(legend.position="none")
nytimes_tf_idf %>%
filter(term %in% c("trump","obama","clinton","health","obamacar","russia")) %>%
ggplot(aes(x=date,
y=tf_idf,
color=term),
size=0.5,
alpha=1) +
geom_point() +
geom_smooth() +
facet_wrap(~term) +
scale_x_date(labels=date_format("%Y-%m"))+
scale_colour_brewer(palette="Set1")+
ggtitle("TF-IDF for Words ")+
theme_fivethirtyeight()+
theme(legend.position="none")
nytimes_tf_idf %>%
filter(term %in% c("trump","obama","clinton","health","obamacar","russia")) %>%
ggplot(aes(x=date,
y=tf_idf,
color=term),
size=0.5,
alpha=1) +
geom_point() +
geom_smooth() +
facet_wrap(~term) +
scale_x_date(labels=date_format("%Y-%m"))+
scale_colour_brewer(palette="Set1")+
ggtitle("TF-IDF for Words ")+
theme_solarized()+
theme(legend.position="none")
nytimes_tf_idf %>%
filter(term %in% c("trump","obama","clinton","health","obamacar","russia")) %>%
ggplot(aes(x=date,
y=tf_idf,
color=term),
size=0.5,
alpha=1) +
geom_point() +
geom_smooth() +
facet_wrap(~term) +
scale_x_date(labels=date_format("%Y-%m"))+
scale_colour_brewer(palette="Set1")+
ggtitle("TF-IDF for Words ")+
theme_fivethirtyeight()+
theme(legend.position="none")
nytimes_tf_idf %>%
filter(term %in% c("trump","obama","clinton","health","obamacar","russia")) %>%
ggplot(aes(x=date,
y=tf_idf,
color=term),
size=0.5,
alpha=1) +
geom_point() +
geom_smooth() +
facet_wrap(~term) +
scale_x_date(labels=date_format("%Y-%m"))+
scale_colour_brewer(palette="Set1")+
ggtitle("TF-IDF for Words ")+
theme_fivethirtyeight()+
theme(legend.position="none",
axis.title.x=element_text())
nytimes_tf_idf %>%
filter(term %in% c("trump","obama","clinton","health","obamacar","russia")) %>%
ggplot(aes(x=date,
y=tf_idf,
color=term),
size=0.5,
alpha=1) +
geom_point() +
geom_smooth() +
facet_wrap(~term) +
scale_x_date(labels=date_format("%Y-%m"))+
scale_colour_brewer(palette="Set1")+
ggtitle("TF-IDF for Words ")+
theme_fivethirtyeight()+
theme(legend.position="none",
axis.title.x=element_text())
nytimes_tf_idf %>%
filter(term %in% c("trump","obama","clinton","health","obamacar","russia")) %>%
ggplot(aes(x=date,
y=tf_idf,
color=term),
size=0.5,
alpha=1) +
geom_point() +
geom_smooth() +
facet_wrap(~term) +
xlab("date")+
scale_x_date(labels=date_format("%Y-%m"))+
scale_colour_brewer(palette="Set1")+
ggtitle("TF-IDF for Words ")+
theme_fivethirtyeight()+
theme(legend.position="none",
axis.title.x=element_text())
nytimes_tf_idf %>%
filter(term %in% c("trump","obama","clinton","health","obamacar","russia")) %>%
ggplot(aes(x=date,
y=tf_idf,
color=term),
size=0.5,
alpha=1) +
geom_point() +
geom_smooth() +
facet_wrap(~term) +
scale_x_date(labels=date_format("%Y-%m"))+
scale_colour_brewer(palette="Set1")+
ggtitle("TF-IDF for Words ")+
theme(legend.position="none")
nytimes_tf_idf %>%
filter(term %in% c("trump")) %>%
ggplot(aes(x=date,
y=tf_idf,
color=author)) +
geom_point() +
geom_smooth() +
facet_wrap(~author) +
scale_x_date(labels=date_format("%Y-%m"))+
scale_colour_brewer(palette="Set1")+
ggtitle("TF-IDF for Word 'Trump' over time")+
theme(legend.position="none")
tidy_df %>%
filter(subject %in% top_5_subjects$subject) %>%
ggplot(aes(x=subject,
y=FRE_nytimes,
fill=subject)) +
geom_boxplot()+
xlab(NULL)+
ylab("Flesch-Kincaid Grade Levels")+
scale_fill_brewer(palette="Set1")+
facet_wrap(~author,scales="free_x")+
theme(axis.text.x = element_blank())
load("C:/Users/Jung Hoon Son/OneDrive/Coursework/DBMI/QMSS4063/final-project-team-tweets/trump_tweets.RData")
rm(c2009)
rm(c2010)
rm(c2011)
rm(c2012)
rm(all_tweets_grouped)
rm(dt)
rm(df)
rm(tidy_df)
rm(neg)
rm(pos)
rm(subjects)
rm(c2017)
rm(c2016)
rm(FRE_nytimes)
rm(topic_array)
rm(topic_num)
rm(c2015)
rm(c2014)
rm(c2013)
rm(associations_df)
rm(top_5_subjects)
rm(top_8_subjects)
save.image("C:/Users/Jung Hoon Son/OneDrive/Coursework/DBMI/QMSS4063/HW4/assignment-4-interactive-visuals-plasmak11/trump_tweets.RData")
load("C:/Users/Jung Hoon Son/Desktop/QMSS4063workspace/.RData")
library(jsonlite)
library(quanteda)
library(tm)
library(qdap)
library(qdapDictionaries)
library(tidytext)
library(dplyr)
library(stringr)
library(lubridate)
library(tidytext)
library(ggplot2)
library(ggthemes)
library(scales)
load("C:/Users/Jung Hoon Son/OneDrive/Coursework/DBMI/QMSS4063/final-project-team-tweets/.RData")
install.packages('rshiny')
install.packages('shiny')
library(shiny)
ui <- fluidPage(
# input()
# output()
sliderInput(inputId="min_freq",
label="Minimum Frequency:",
value=15,min=1,max=100),
sliderInput(inputId="max_freq",
label="Maximum Frequency:",
value=100,min=1,max=300),
plotOutput("wordcloud")
)
server<-function(input,output){
output$wordcloud <- renderPlot({
wordcloud(input$min_freq)
})
}
shinyapp(ui=ui,server=server)
library(shiny)
shinyapp(ui=ui,server=server)
shinypp(ui=ui,server=server)
shinyApp(ui=ui,server=server)
library(shiny)
library(wordcloud)
ui <- fluidPage(
# input()
# output()
sliderInput(inputId="min_freq",
label="Minimum Frequency:",
value=15,min=1,max=100),
sliderInput(inputId="max_freq",
label="Maximum Frequency:",
value=100,min=1,max=300),
plotOutput("wordcloud")
)
server<-function(input,output){
output$wordcloud <- renderPlot({
wordcloud(input$min_freq)
})
}
shinyApp(ui=ui,server=server)
library(DT)
?datatable
View(all_tweets)
library(DT)
all_tweets_filtered<-all_tweets %>%
select(source,
Tweets=text,
created_at,
topic.name)
library(dplyr)
all_tweets_filtered<-all_tweets %>%
select(source,
Tweets=text,
created_at,
topic.name)
datatable(all_tweets_filtered)
library(shiny)
library(shiny)
shinyApp(
ui = fluidPage(
tags$head(tags$style(HTML("input[type='search']:disabled {visibility:hidden}"))),
DT::dataTableOutput('tbl')),
server = function(input, output) {
iris2 = head(iris, 10)
output$tbl = DT::renderDataTable(
datatable(iris2, filter = 'top',
options = list(
columnDefs = list(list(targets = c(1, 3), searchable = FALSE)),
pageLength = 5
)
))
}
)
library(shiny)
shinyApp(
ui = fluidPage(
tags$head(tags$style(HTML("input[type='search']:disabled {visibility:hidden}"))),
DT::dataTableOutput('tbl')),
server = function(input, output) {
iris2 = head(iris, 10)
output$tbl = DT::renderDataTable(
datatable(all_tweets_filtered, filter = 'top',
options = list(
columnDefs = list(list(targets = c(4,5), searchable = FALSE)),
pageLength = 5
)
))
}
)
load("C:/Users/Jung Hoon Son/OneDrive/Coursework/DBMI/BINF4002/tcrd-similar-targets/workspace_20170508.RData")
##################33
bah<-all_tcrd
idl_idgfam<-read.csv("all_tcrd_tdl_idgfam.csv")
colnames(idl_idgfam)[1]<-"target_id"
# bah<-cbind(bah,data.frame(idl_idgfam[match(all_tcrd$target_id, idl_idgfam$target_id),])$tdl)
# colnames(bah)[88598]<-'tdl'
bah<-cbind(bah,data.frame(idl_idgfam[match(all_tcrd$target_id, idl_idgfam$target_id),])$idgfam)
colnames(bah)[88598]<-'idgfam'
bah$predict<-predict(model,bah)
table(bah$predict,bah$tdl)
table(bah$predict,bah$idgfam)
# table(bah$predict,bah$chembl_activity_CHEMBL42_Ki)
# table(bah$predict,bah$drug_activity_Cytosol)
# table(bah$tdl,bah$drug_activity_Cytosol)
# table(bah$predict,bah$tdl)
library(heatmap3)
rownames(bah)<-bah[,which(colnames(bah)=="target_id")]
cols_to_subtract<-c(which(colnames(bah)=="target_id"),
which(colnames(bah)=="tdl"),
which(colnames(bah)=="idgfam"),
which(colnames(bah)=="predict"))
heatmap_mat<-data.matrix(bah[,-cols_to_subtract])
heatmap_mat<-heatmap_mat[,colSums(heatmap_mat) > 40]
library(ComplexHeatmap)
library(colorspace)
dev.off()
idgfam_annotation<-data.frame()
idgfam_annotation<-data.frame(idgfam=bah[bah$target_id == as.numeric(rownames(heatmap_mat))]$idgfam,
tdl=bah[bah$target_id == as.numeric(rownames(heatmap_mat))]$tdl,
predict=bah[bah$target_id == as.numeric(rownames(heatmap_mat))]$predict)
temp<-all_tcrd_reduced[,colSums(all_tcrd_reduced) > 40]
# merge our gold standards
temp<-merge(temp,all_gold[,c('id','tdl','idgfam','y')],by.x='target_id',by.y='id')
# Exclude the target_id column for training
temp<-temp[,c(-1)]
# Split the sample at even distribution using our y gold standard label
library(caTools)
spl<-sample.split(temp$y,SplitRatio = 0.8)
all_tcrd_reduced_train<-temp[spl,]
all_tcrd_reduced_test<-temp[!spl,]
library(e1071)
library(randomForest)
library(caret)
# Make sure y is a factor
all_tcrd_reduced_train$y<-as.factor(all_tcrd_reduced_train$y)
which(colnames(all_tcrd_reduced_train)=="tdl")
which(colnames(all_tcrd_reduced_train)=="idgfam")
# model <- naiveBayes(y~.-tdl-idgfam,data=all_tcrd_reduced_train)
# model<-randomForest(y~.-tdl-idgfam,data=all_tcrd_reduced_train)
model<-randomForest(y~.-tdl-idgfam,data=all_tcrd_reduced_train)
pred <- predict(model,all_tcrd_reduced_test[,c(-which(colnames(all_tcrd_reduced_test)=="y"))])
table(pred, all_tcrd_reduced_test$y)
View(varImp(model))
##################33
bah<-all_tcrd
idl_idgfam<-read.csv("all_tcrd_tdl_idgfam.csv")
colnames(idl_idgfam)[1]<-"target_id"
# bah<-cbind(bah,data.frame(idl_idgfam[match(all_tcrd$target_id, idl_idgfam$target_id),])$tdl)
# colnames(bah)[88598]<-'tdl'
bah<-cbind(bah,data.frame(idl_idgfam[match(all_tcrd$target_id, idl_idgfam$target_id),])$idgfam)
colnames(bah)[88598]<-'idgfam'
bah$predict<-predict(model,bah)
table(bah$predict,bah$tdl)
table(bah$predict,bah$idgfam)
# table(bah$predict,bah$chembl_activity_CHEMBL42_Ki)
# table(bah$predict,bah$drug_activity_Cytosol)
# table(bah$tdl,bah$drug_activity_Cytosol)
# table(bah$predict,bah$tdl)
library(heatmap3)
rownames(bah)<-bah[,which(colnames(bah)=="target_id")]
cols_to_subtract<-c(which(colnames(bah)=="target_id"),
which(colnames(bah)=="tdl"),
which(colnames(bah)=="idgfam"),
which(colnames(bah)=="predict"))
heatmap_mat<-data.matrix(bah[,-cols_to_subtract])
heatmap_mat<-heatmap_mat[,colSums(heatmap_mat) > 40]
library(ComplexHeatmap)
library(colorspace)
dev.off()
idgfam_annotation<-data.frame()
idgfam_annotation<-data.frame(idgfam=bah[bah$target_id == as.numeric(rownames(heatmap_mat))]$idgfam,
tdl=bah[bah$target_id == as.numeric(rownames(heatmap_mat))]$tdl,
predict=bah[bah$target_id == as.numeric(rownames(heatmap_mat))]$predict)
pdf("heatmap.pdf",width=40,height=50)
# ha1 = HeatmapAnnotation(df = df,
#                         col = list(type = c("a" = "red", "b" = "blue"),
#                                    age = colorRamp2(c(0, 20), c("white", "red"))))
# ha2 = HeatmapAnnotation(df = data.frame(age = sample(1:20, 10)),
#                         col = list(age = colorRamp2(c(0, 2), c("IC", "GPCR","Kinase"))))
setwd("C:/Users/Jung Hoon Son/OneDrive/Coursework/DBMI/BINF4002/tcrd-similar-targets")
library(heatmap3)
rownames(bah)<-bah[,which(colnames(bah)=="target_id")]
cols_to_subtract<-c(which(colnames(bah)=="target_id"),
which(colnames(bah)=="tdl"),
which(colnames(bah)=="idgfam"),
which(colnames(bah)=="predict"))
heatmap_mat<-data.matrix(bah[,-cols_to_subtract])
heatmap_mat<-heatmap_mat[,colSums(heatmap_mat) > 40]
install.packages("qgraph")
install.packages("corrplot")
library(qgraph)
library(parcor)
cor<-cor(heatmap_mat)
Heatmap(cor)
library(ComplexHeatmap)
library(colorspace)
library(qgraph)
install.packages("qgraph")
library(qgraph)
library(qgraph)
library(ComplexHeatmap)
install.packages("ComplexHeatmap")
library(ComplexHeatmap)
